import requests
from bs4 import BeautifulSoup
import cloudscraper
from telegram import Bot
import asyncio
import os

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')

async def send_telegram_message(message):
    bot = Bot(token=TELEGRAM_BOT_TOKEN)
    await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message, parse_mode='HTML')



def scrape_aljazeera():
    url = "https://www.aljazeera.net/news/"
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    articles = []
    for link in soup.find_all('a', class_='u-clickable-card__link'):
        title = link.text.strip()
        href = link.get('href')
        if title and href:
            # Construct full URL properly
            if href.startswith('/'):
                full_url = "https://www.aljazeera.net" + href
            elif href.startswith('http'):
                full_url = href
            else:
                full_url = url + href
            
            articles.append({'title': title, 'url': full_url})
    return articles

def filter_military_news(articles):
    keywords = [
        "Ø­Ø±Ø¨", "Ø¹Ø³ÙƒØ±ÙŠ", "Ø¬ÙŠØ´", "ØµØ±Ø§Ø¹", "Ù†Ø²Ø§Ø¹", "Ù‚ØªØ§Ù„", "Ù‚ØµÙ", "ØµØ§Ø±ÙˆØ®", "Ø·Ø§Ø¦Ø±Ø© Ø­Ø±Ø¨ÙŠØ©",
        "Ø¯Ø¨Ø§Ø¨Ø©", "Ø³Ù„Ø§Ø­", "Ø§Ø´ØªØ¨Ø§Ùƒ", "Ù‡Ø¬ÙˆÙ…", "Ø¯ÙØ§Ø¹", "Ø§Ø­ØªÙ„Ø§Ù„", "ØªØ­Ø±ÙŠØ±", "Ø´Ù‡ÙŠØ¯", "Ø¶Ø­Ø§ÙŠØ§",
        "Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„", "ÙÙ„Ø³Ø·ÙŠÙ†", "ØºØ²Ø©", "Ø§Ù„Ù‚Ø¯Ø³", "Ø§Ù„Ø¶ÙØ© Ø§Ù„ØºØ±Ø¨ÙŠØ©", "Ø¥ÙŠØ±Ø§Ù†", "Ø£Ù…Ø±ÙŠÙƒØ§", "Ø±ÙˆØ³ÙŠØ§",
        "Ø£ÙˆÙƒØ±Ø§Ù†ÙŠØ§", "Ø³ÙˆØ±ÙŠØ§", "Ø§Ù„ÙŠÙ…Ù†", "Ù„Ø¨Ù†Ø§Ù†", "Ø­Ø²Ø¨ Ø§Ù„Ù„Ù‡", "Ø­Ù…Ø§Ø³", "Ø¬Ù‡Ø§Ø¯", "Ø¥Ø±Ù‡Ø§Ø¨", "Ø¯Ø§Ø¹Ø´",
        "Ù‚ÙˆØ§Øª", "ÙƒØªØ§Ø¦Ø¨", "Ù„ÙˆØ§Ø¡", "ÙÙŠÙ„Ù‚", "Ø¬Ø¨Ù‡Ø©", "Ù…Ø¹Ø±ÙƒØ©", "Ø¹Ù…Ù„ÙŠØ© Ø¹Ø³ÙƒØ±ÙŠØ©", "ØªÙ‡Ø¯ÙŠØ¯", "Ø¹Ù‚ÙˆØ¨Ø§Øª",
        "Ø§ØªÙØ§Ù‚ÙŠØ© Ø³Ù„Ø§Ù…", "Ù‡Ø¯Ù†Ø©", "ÙˆÙ‚Ù Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„Ù†Ø§Ø±", "Ù…ÙØ§ÙˆØ¶Ø§Øª", "Ø£Ù…Ù†", "Ø§Ø³ØªØ®Ø¨Ø§Ø±Ø§Øª", "ØªØ¬Ø³Ø³",
        "Ø§Ù†ÙØ¬Ø§Ø±", "Ø§ØºØªÙŠØ§Ù„", "Ø§Ù†Ù‚Ù„Ø§Ø¨", "ØªÙ…Ø±Ø¯", "Ø«ÙˆØ±Ø©", "Ù„Ø§Ø¬Ø¦ÙŠÙ†", "Ù†Ø²ÙˆØ­", "Ø­ØµØ§Ø¯", "Ø®Ø³Ø§Ø¦Ø±",
        "Ø¯Ù…Ø§Ø±", "Ø¥ØºØ§Ø«Ø©", "Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø¥Ù†Ø³Ø§Ù†ÙŠØ©", "Ù…Ø¬Ø§Ø¹Ø©", "Ø­ØµØ§Ø¯", "ØªØ¯Ù…ÙŠØ±", "Ø¹Ù†Ù", "ØªÙˆØªØ±", "ØªØµØ¹ÙŠØ¯"
    ]
    filtered_articles = []
    for article in articles:
        for keyword in keywords:
            if keyword in article['title']:
                filtered_articles.append(article)
                break # Move to the next article once a keyword is found
    return filtered_articles

def format_arabic_message(title, url):
    """Format message with proper RTL Arabic text and URL alias"""
    # Add RTL control characters for proper Arabic display
    rtl_title = f"\u202B{title}\u202C"  # RTL embedding characters
    
    # Format with HTML for better display using "See Source" as alias
    message = f"<b>{rtl_title}</b>\n\nğŸ”— <a href='{url}'>See Source</a>"
    return message

async def main():
    print("Scraping Al Jazeera...")
    aljazeera_articles = scrape_aljazeera()
    print(f"Found {len(aljazeera_articles)} articles from Al Jazeera.")
    
    print("Filtering military and war-related news...")
    military_news = filter_military_news(aljazeera_articles)
    print(f"Found {len(military_news)} military and war-related articles.")
    
    for article in military_news:
        message = format_arabic_message(article['title'], article['url'])
        print(message)
        await send_telegram_message(message)
        print("---")

if __name__ == '__main__':
    asyncio.run(main())